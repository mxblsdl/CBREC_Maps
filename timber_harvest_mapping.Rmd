---
title: "CBREC LCA Analysis of Timber Harvest Projects from 2016 - 2019"
author: "Max Blasdel"
date: "August 11, 2020"
output:
  html_document: default
---

# Purpose
Create final maps from CBREC outputs for use in results report
  
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

# Setup
Set user defined variables

## Define Scenarios
These are variables that set the definition of the scenario. I could move the functional unit into this 
```{r}
#ref_scen <- "Pile and Broadcast"
ref_scen <- "None"
```

Load libraries and helper functions

```{r results='hide'}
#source("R/CBI_postFunctions.R")
#source("R/CBI_filterHarvests.R")

library(data.table) # data structure
library(tictoc) # time test
library(praise) # why not?
library(tidyverse)
library(ggridges) # additional ridge plotting
library(ggplot2) # plotting
library(sf)
```

Define helper functions
```{r include=TRUE}
# bind data into data table function; works with specific list structure of outputs
bindDataTable <- function(data) {
  require(data.table)
  tr <-
    lapply(data, function(d) {
      # simplify list structure
      d <- unlist(d, recursive = F)
      # bind together as data table
      d <- rbindlist(d)
      return(d)
    })
  return(tr)
}

# for use in subsetting the scenario matrix based on map specifications
scenario_function <- function(scenario_matrix, 
                              piled, # will be the same for use and reference 
                              use_collection, 
                              use_burn,
                              ref_collection = "No",
                              ref_burn,
                              negate_ref){
  
  use <- subset(scenario_matrix, Fraction_Piled == piled & 
           Biomass_Collection == use_collection &
           Burn_Type == use_burn)
  
  # allow for no reference case burn to be explicitly defined
  if(negate_ref) {
      ref <- subset(scenario_matrix, Fraction_Piled == piled & 
             Biomass_Collection == ref_collection &
             Burn_Type != ref_burn)
  } else {
    ref <- subset(scenario_matrix, Fraction_Piled == piled & 
             Biomass_Collection == ref_collection & 
             Burn_Type == ref_burn)
  }
  
 return(list("use_id" = use$ID, 
             "ref_id"= ref$ID)) 
}

## ggplot theme
mxblsdl <- theme_minimal(base_size = 12) +
  theme(legend.position = "bottom",
        #legend.title = element_blank(),
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 12))

# set the theme for all plots
theme_set(mxblsdl)
```

# Load Data

## Model outputs
First find the model results which are classified by the 'metric', either kWh or MT Recovered.
Using MT Recovered per Kevin's email.
```{r include=TRUE}
# find all results files
files <- dir("CBREC_Model_Output/MTrecovered", full.names = T, recursive = T)
length(files)
# find files which are larger than a certain size and have data
```

## Spatial Data
These are timber harvests from all years

```{r}
sf_path <- dir("CBREC-LCA_timber_activity_polygons_2016-2019", pattern = ".shp$", full.names = T)
harvests <- read_sf(sf_path)
```

## Scenario data
This includes the scenario pairings and the scenario IDs
```{r}
scenario_paths <- dir("inst", full.names = T)

scen_pairings <- fread(scenario_paths[1])
scen_mat <- fread(scenario_paths[2])

# remove pulp market
scen_mat[, Pulp_Market := NULL]

# inspect
head(scen_mat)
```

Define the use and reference scenarios
It would be good to make a function here since this will be run a number of times...

This function is what changes based on the map specifications.
```{r}
ids <- scenario_function(scenario_matrix = scen_mat,
                  piled = 50,
                  use_collection = "All Tech Recoverable",
                  use_burn = "None",
                  ref_burn = ref_scen)

poly_num <- tools::file_path_sans_ext(gsub(".*/", "", unlist(files)))
```

# Read the output data and filter based on the scenarios

Data is structured in a list format only showing the time series emissions. I need to filter based on the Use first and then reference. The net emissions for each category are shown in the name of the list.
#TODO
filter by reference as well.
```{r include=TRUE}
# Read and filter based on reference ids first
data <- lapply(files, function(file) {
  dat <-
    readRDS(file)
  # get polygon number
  poly_num <- tools::file_path_sans_ext(gsub(".*/", "", unlist(file)))

  da <- dat[grepl(paste0("\\b", ids[["ref_id"]], "\\b", collapse = "|"), names(dat))]
  
  # attach polygon number
  #da[["poly_num"]] <- poly_num
  return(da)
})

# each list should be length one

## May not need this second filter
# Further filter based on selected use case
data <-
  lapply(data, function(file) {
    file[grepl(paste0("\\b", ids[["use_id"]], "\\b",collapse = "|"), names(file))]
  })

# simplify list structure
data <- unlist(data, recursive = F)
```

# Extract important information from data

Bind the polygon number to the values as well. The polygon number or `poly_num` will be used to join the spatial data. 
```{r}
out <- lapply(data, function(d) {
  # AGWP and AGTP are both the same for every year of the time series
  vals <- d$time_series[, .(net.MT_CO2e.AGWP.100yr, net.MT_CO2e.AGTP.100yr, MT_Residue_Mobilized, MT_Residue_Mobilized_perAcre)] %>%
    distinct()
  
  return(vals)
})

# bind together
data <- rbindlist(out)
```

Bind polygon number onto data

```{r}
# get polygon number
poly_num <- tools::file_path_sans_ext(gsub(".*/", "", unlist(files)))

data[["poly_num"]] <- poly_num
```

# Bind with spatial data

```{r}
# TODO check on units
# convert data to correct units; This is the difference between MT and grams
data <-
  data %>%
  mutate(AGTP_co2e_kg = net.MT_CO2e.AGTP.100yr * 1000,
         AGWP_co2e_kg = net.MT_CO2e.AGWP.100yr * 1000)

# set names for join
#setnames(data, 'V1', 'polys')

# rename ID for join
harvests <- harvests %>%
      rename(poly_num = OBJECTID) %>%
      mutate(poly_num = as.character(poly_num))

# join by polygon ID
data <- left_join(data, harvests, by = "poly_num")
```

# Filter data based on criteria

```{r}
filtered_data <- data %>% 
  filter(MT_Residue_Mobilized >= 1)
```

# Plotting
## Historgram with nice gradient

```{r}
if(ref_scen == "None") {t = "No Burn"} else {t = "Pile and Broadcast"}
#g <-
filtered_data %>% 
  ggplot(aes(x = AGTP_co2e_kg, fill = ..x..)) +
  theme_minimal() +
  geom_histogram(binwidth = 10, show.legend = F) +
  scale_fill_gradient(low = "#63B8FF", high = "#CD950C") +
  labs(title = paste(t, "Counterfactul"),
       x = expression("kilograms CO"[2]~"e per MT Recovered"),
       y = "Count") +
  theme(text = element_text(size = 16))
```

# Write for use in QGIS

```{r}
write_sf(filtered_data, "Q/input/harvests.gpkg", layer = ref_scen, delete_layer = T)
```

# Prepare Data for maps 4-8

```{r}
ids <- scenario_function(scenario_matrix = scen_mat,
                  piled = 50,
                  use_collection = "All Tech Recoverable",
                  use_burn = "None",
                  ref_burn = "None", 
                  negate_ref = T)
# special reference for Rx purn
# ref <- subset(scenario_matrix, Fraction_Piled == piled & 
#              Biomass_Collection == ref_collection & 
#              Burn_Type != "None")

data <- lapply(files, function(file) {
  dat <- readRDS(file)
  da <- dat[grepl(paste0("\\b", ids[["ref_id"]], "\\b", collapse = "|"), names(dat))]
  return(da)
})

data <- lapply(data, function(d) {
  da <- d[grepl(paste0("\\b", ids[["use_id"]], "\\b", collapse = "|"), names(d))]
  return(da)
})

# simplify list structure
data <- unlist(data, recursive = F)

# Missing SOX NEED TO EMAIL ABOUT
out <- lapply(data, function(d) {
  # AGWP and AGTP are both the same for every year of the time series
  vals <- d$time_series[, .(net.CH4_MTperMT_Mobilized,
                            net.N2O_MTperMT_Mobilized,
                            net.PM2.5_MTperMT_Mobilized,
                            MT_Residue_Mobilized, 
                            MT_Residue_Mobilized_perAcre)] %>%
    slice(1)
  return(vals)
})

# bind together
data <- rbindlist(out)

# paste polygon number into
data[["poly_num"]] <- poly_num
```

# Spatial Join

```{r}
# TODO check on units
# convert data to correct units; This is the difference between MT and grams
data <-data %>% 
  mutate(AGTP_co2e_kg = net.MT_CO2e.AGTP.100yr * 1000,
         AGWP_co2e_kg = net.MT_CO2e.AGWP.100yr * 1000)

# join by polygon ID
data <- left_join(data, harvests, by = "poly_num")
```

Filter data based on size of harvest
```{r}
filtered_data <- data %>% 
  filter(MT_Residue_Mobilized >= 1)
```


```{r}
write_sf(filtered_data, "Q/input/harvests.gpkg", layer = "criteriants", delete_layer = T)
```

